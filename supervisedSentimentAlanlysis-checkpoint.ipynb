{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4e7541",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS\n",
    "### Dataset Information\n",
    "The main goal of this project is to identify speech containing hate speech in tweets. To simplify the classification process, we consider a tweet to contain hate speech if it expresses racist or sexist sentiments. Consequently, the task involves categorizing tweets into two groups: those containing hate speech (labeled as 1) and those that do not (labeled as 0).\n",
    "\n",
    "Formally, the objective is to create a model that can predict the labels for the test dataset based on a training sample of tweets and their corresponding labels. In the training dataset, each tweet is associated with a label, where label 1 signifies the presence of hate speech and label 0 indicates the absence of hate speech.\n",
    "\n",
    "The training dataset comprises 12,488 tweets and their respective labels. This data is available in CSV format, with each line of the file containing a tweet ID, its corresponding label, and the content of the tweet.\n",
    "\n",
    "The ultimate aim is to develop a robust classification model that can accurately distinguish between tweets that contain hate speech and those that do not, enabling the detection and handling of potentially harmful content on social media platforms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ea4b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "    horizontal-align: middle;\n",
       "}\n",
       "h1,h2 {\n",
       "    text-align: center;\n",
       "    background-color: pink;\n",
       "    padding: 20px;\n",
       "    margin: 0;\n",
       "    color: black;\n",
       "    font-family: ariel;\n",
       "    border-radius: 80px\n",
       "}\n",
       "\n",
       "h3 {\n",
       "    text-align: center;\n",
       "    border-style: solid;\n",
       "    border-width: 3px;\n",
       "    padding: 12px;\n",
       "    margin: 0;\n",
       "    color: black;\n",
       "    font-family: ariel;\n",
       "    border-radius: 80px;\n",
       "    border-color: gold;\n",
       "}\n",
       "\n",
       "body, p {\n",
       "    font-family: ariel;\n",
       "    font-size: 15px;\n",
       "    color: charcoal;\n",
       "}\n",
       "div {\n",
       "    font-size: 14px;\n",
       "    margin: 0;\n",
       "\n",
       "}\n",
       "\n",
       "h4 {\n",
       "    padding: 0px;\n",
       "    margin: 0;\n",
       "    font-family: ariel;\n",
       "    color: purple;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "    horizontal-align: middle;\n",
    "}\n",
    "h1,h2 {\n",
    "    text-align: center;\n",
    "    background-color: pink;\n",
    "    padding: 20px;\n",
    "    margin: 0;\n",
    "    color: black;\n",
    "    font-family: ariel;\n",
    "    border-radius: 80px\n",
    "}\n",
    "\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    border-style: solid;\n",
    "    border-width: 3px;\n",
    "    padding: 12px;\n",
    "    margin: 0;\n",
    "    color: black;\n",
    "    font-family: ariel;\n",
    "    border-radius: 80px;\n",
    "    border-color: gold;\n",
    "}\n",
    "\n",
    "body, p {\n",
    "    font-family: ariel;\n",
    "    font-size: 15px;\n",
    "    color: charcoal;\n",
    "}\n",
    "div {\n",
    "    font-size: 14px;\n",
    "    margin: 0;\n",
    "\n",
    "}\n",
    "\n",
    "h4 {\n",
    "    padding: 0px;\n",
    "    margin: 0;\n",
    "    font-family: ariel;\n",
    "    color: purple;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14840d07",
   "metadata": {},
   "source": [
    "## IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42cd216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\patty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\patty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\patty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\patty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\patty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2264\\4188339153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m# WordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageColorGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# Utility\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# WordCloud\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08907343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Twitter_Data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c74737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e922e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32744d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
